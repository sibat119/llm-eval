{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sibat/miniconda3/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_fields=[\"high_school_computer_science\", \"philosophy\", \"public_relations\"]\n",
    "prompt_strategies=[\"black_box\"]\n",
    "selection_strategies=[\"similarity\"]\n",
    "\n",
    "# Base models\n",
    "llama=\"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "qwen=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "batch_size=16\n",
    "shot=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Dataset({\n",
       "      features: ['zero_shot_response', 'few_shot_response', 'black_box_response', 'prompt', 'zero_shot_top_index', 'few_shot_top_index', 'prompt_pick_cosine_sim_zero', 'prompt_pick_cosine_sim_few'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  '/home/sibat/repoes/llm-eval/data/dataset/surrogate/high_school_computer_science/black_box/5-shot-similarity-selection/agreement-to-disagreement-candidate-meta-llama-Llama-3.1-8B-Instruct-surrogate-Qwen-Qwen2.5-7B-Instruct.csv'),\n",
       " (Dataset({\n",
       "      features: ['zero_shot_response', 'few_shot_response', 'black_box_response', 'prompt', 'zero_shot_top_index', 'few_shot_top_index', 'prompt_pick_cosine_sim_zero', 'prompt_pick_cosine_sim_few'],\n",
       "      num_rows: 25\n",
       "  }),\n",
       "  '/home/sibat/repoes/llm-eval/data/dataset/surrogate/philosophy/black_box/5-shot-similarity-selection/agreement-to-disagreement-candidate-meta-llama-Llama-3.1-8B-Instruct-surrogate-Qwen-Qwen2.5-7B-Instruct.csv'),\n",
       " (Dataset({\n",
       "      features: ['zero_shot_response', 'few_shot_response', 'black_box_response', 'prompt', 'zero_shot_top_index', 'few_shot_top_index', 'prompt_pick_cosine_sim_zero', 'prompt_pick_cosine_sim_few'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  '/home/sibat/repoes/llm-eval/data/dataset/surrogate/public_relations/black_box/5-shot-similarity-selection/agreement-to-disagreement-candidate-meta-llama-Llama-3.1-8B-Instruct-surrogate-Qwen-Qwen2.5-7B-Instruct.csv')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_a2d_datasets = []\n",
    "all_d2a_datasets = []\n",
    "for sub_field in sub_fields:\n",
    "    for selection_strategy in selection_strategies:\n",
    "        for prompt_variation in prompt_strategies:\n",
    "            surrogate_dir = os.path.join('/home/sibat/repoes/llm-eval/data/dataset', 'surrogate', sub_field, prompt_variation, f\"{shot}-shot-{selection_strategy}-selection\")\n",
    "            candidate_llm = llama\n",
    "            surrogate_llm = qwen\n",
    "            ds_path = f\"{surrogate_dir}/agreement-to-disagreement-candidate-{candidate_llm.replace('/', '-')}-surrogate-{surrogate_llm.replace('/', '-')}.csv\"\n",
    "            ds = Dataset.from_csv(ds_path)\n",
    "            all_a2d_datasets.append((ds, ds_path))\n",
    "            ds_path = f\"{surrogate_dir}/disagreement-to-agreement-candidate-{candidate_llm.replace('/', '-')}-surrogate-{surrogate_llm.replace('/', '-')}.csv\"\n",
    "            try:\n",
    "                ds = Dataset.from_csv(ds_path)\n",
    "                all_d2a_datasets.append((ds, ds_path))\n",
    "            except:\n",
    "                all_d2a_datasets.append((\"\", ds_path))\n",
    "                \n",
    "            # candidate_llm = qwen\n",
    "            # surrogate_llm = llama\n",
    "            # ds_path = f\"{surrogate_dir}/agreement-to-disagreement-candidate-{candidate_llm.replace('/', '-')}-surrogate-{surrogate_llm.replace('/', '-')}.csv\"\n",
    "            # ds = Dataset.from_csv(ds_path)\n",
    "            # all_a2d_datasets.append((ds, ds_path))\n",
    "            # ds_path = f\"{surrogate_dir}/disagreement-to-agreement-candidate-{candidate_llm.replace('/', '-')}-surrogate-{surrogate_llm.replace('/', '-')}.csv\"\n",
    "            # try:\n",
    "            #     ds = Dataset.from_csv(ds_path)\n",
    "            #     all_d2a_datasets.append((ds, ds_path))\n",
    "            # except:\n",
    "            #     all_d2a_datasets.append((\"\", ds_path))\n",
    "\n",
    "all_a2d_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-candidate-meta-llama-Llama-3.1-8B-Instruct-surrogate-Qwen-Qwen2.5-7B-Instruct.csv']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index +=1\n",
    "ds_a2d, dspath_a2d = all_a2d_datasets[index]\n",
    "ds_d2a, dspath_d2a = all_d2a_datasets[index]\n",
    "i = -1\n",
    "j = -1\n",
    "dspath_a2d.split('agreement-to-disagreement')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "zero_shot_response\n",
      "are not objective.\n",
      "few_shot_response\n",
      "are self-evident.\n",
      "black_box_response\n",
      "are self-evident.\n",
      "zero_shot_top_index\n",
      "3\n",
      "few_shot_top_index\n",
      "1\n",
      "prompt_pick_cosine_sim_zero\n",
      "0.1242207810282707\n",
      "prompt_pick_cosine_sim_few\n",
      "0.1340645253658294\n",
      "prompt\n",
      "Your goal is to predict what the black-box model will answer to a given question. Below are examples of inputs (questions) and the black-box model's actual responses.\n",
      "\n",
      "The black-box LLM saw the following instructions each time it answered:\n",
      "1. System instruction: \"You are a helpful AI assistant answering questions. Provide only accurate answers in natural language.\"\n",
      "2. Prompt structure given to black-box LLM:\n",
      "  \"\"\"\n",
      "  Given the following question and candidate answers, choose the best answer. \n",
      "  Do not include option labels (A, B, C, D); respond only with natural answer text. \n",
      "  Provide only the answer text in your response.\n",
      "\n",
      "  Question: <question_text>\n",
      "  Options: <option_texts>\n",
      "  \"\"\"\n",
      "\n",
      "Examples of the Black-Box LLM in Action:\n",
      "Example 1:\n",
      "Question: \"Ross claims that we learn of our prima facie duties:\"\n",
      "Options: \"- by seeing the prima facie rightness of particular acts, and then apprehending general principles.\n",
      "- by apprehending general principles, and then inferring the prima facie rightness of particular acts.\n",
      "- by proving them philosophically.\n",
      "- from the explicit moral instruction we receive as children.\"\n",
      "Response: \"by seeing the prima facie rightness of particular acts, and then apprehending general principles.\"\n",
      "\n",
      "Example 2:\n",
      "Question: \"To explain the notion of a prima facie duty, Ross draws an analogy with:\"\n",
      "Options: \"- natural laws.\n",
      "- the laws of a nation.\n",
      "- the commands of a dictator.\n",
      "- our emotions.\"\n",
      "Response: \"the laws of a nation.\"\n",
      "\n",
      "Example 3:\n",
      "Question: \"Which of the following is not one of Ross’s prima facie duties?\"\n",
      "Options: \"- Fidelity\n",
      "- Beneficence\n",
      "- Non-maleficence\n",
      "- Legality\"\n",
      "Response: \"Non-maleficence is one of Ross's prima facie duties.\"\n",
      "\n",
      "Example 4:\n",
      "Question: \"A prima facie duty is a characteristic of an act in virtue of which the act:\"\n",
      "Options: \"- seems to be right, although this might be illusory.\n",
      "- tends to be right, although this might be outweighed by other considerations.\n",
      "- is right.\n",
      "- is the first thing that an agent ought to do, above all else.\"\n",
      "Response: \"is the first thing that an agent ought to do, above all else.\"\n",
      "\n",
      "Example 5:\n",
      "Question: \"Stevenson claims that the primary use of ethical judgments is to:\"\n",
      "Options: \"- state facts.\n",
      "- influence the interests of others.\n",
      "- describe one’s own approval of things.\n",
      "- none of the above.\"\n",
      "Response: \"describe one’s own approval of things.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Based solely on these examples, predict the most likely response from the black-box model to this new question. \n",
      "New Question: According to Ross, our prima facie duties:\n",
      "Options: - can be proven.\n",
      "- are self-evident.\n",
      "- cannot be known.\n",
      "- are not objective.\n",
      "Your Predicted Black-box LLM Response: (Exact response text only)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "print(i)\n",
    "\n",
    "print(f\"zero_shot_response\")\n",
    "print(f\"{ds_d2a['zero_shot_response'][i]}\")\n",
    "print(f\"few_shot_response\")\n",
    "print(f\"{ds_d2a['few_shot_response'][i]}\")\n",
    "print(f\"black_box_response\")\n",
    "print(f\"{ds_d2a['black_box_response'][i]}\")\n",
    "\n",
    "print(\"zero_shot_top_index\")\n",
    "print(f\"{ds_d2a['zero_shot_top_index'][i]}\")\n",
    "print(\"few_shot_top_index\")\n",
    "print(f\"{ds_d2a['few_shot_top_index'][i]}\")\n",
    "print(\"prompt_pick_cosine_sim_zero\")\n",
    "print(f\"{ds_d2a['prompt_pick_cosine_sim_zero'][i]}\")\n",
    "print(\"prompt_pick_cosine_sim_few\")\n",
    "print(f\"{ds_d2a['prompt_pick_cosine_sim_few'][i]}\")\n",
    "print(f\"prompt\")\n",
    "print(f\"{ds_d2a['prompt'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "zero_shot_response\n",
      "What percent of students attending college in a certain state are majoring in computer science?\n",
      "few_shot_response\n",
      "How many states have a higher percentage of female computer science majors than male computer science majors attending college in that state?\n",
      "black_box_response\n",
      "What percent of students attending college in a certain state are majoring in computer science.\n",
      "zero_shot_top_index\n",
      "2\n",
      "few_shot_top_index\n",
      "1\n",
      "cosine similarity between zero shot picked option and the prompt\n",
      "0.0823778212070465\n",
      "cosine similarity between few shot picked option and the prompt\n",
      "0.0656189322471618\n",
      "prompt\n",
      "Your goal is to predict what the black-box model will answer to a given question. Below are examples of inputs (questions) and the black-box model's actual responses.\n",
      "\n",
      "The black-box LLM saw the following instructions each time it answered:\n",
      "1. System instruction: \"You are a helpful AI assistant answering questions. Provide only accurate answers in natural language.\"\n",
      "2. Prompt structure given to black-box LLM:\n",
      "  \"\"\"\n",
      "  Given the following question and candidate answers, choose the best answer. \n",
      "  Do not include option labels (A, B, C, D); respond only with natural answer text. \n",
      "  Provide only the answer text in your response.\n",
      "\n",
      "  Question: <question_text>\n",
      "  Options: <option_texts>\n",
      "  \"\"\"\n",
      "\n",
      "Examples of the Black-Box LLM in Action:\n",
      "Example 1:\n",
      "Question: \"A programmer is writing a program that is intended to be able to process large amounts of data. Which of the following considerations is LEAST likely to affect the ability of the program to process larger data sets?\"\n",
      "Options: \"- How long the program takes to run\n",
      "- How many programming statements the program contains\n",
      "- How much memory the program requires as it runs\n",
      "- How much storage space the program requires as it runs\"\n",
      "Response: \"How many programming statements the program contains is the least likely to affect the ability of the program to process larger data sets.\"\n",
      "\n",
      "Example 2:\n",
      "Question: \"A retailer that sells footwear maintains a single database containing records with the following information about each item for sale in the retailer's store.\n",
      "\n",
      "   ° Item identification number\n",
      "   ° Footwear type (sneakers, boots, sandals, etc.)\n",
      "   ° Selling price (in dollars)\n",
      "   ° Size\n",
      "   ° Color\n",
      "   ° Quantity available\n",
      "\n",
      " Using only the database, which of the following can be determined?\"\n",
      "Options: \"- Which items listed in the database are not currently in the store\n",
      "- Which colors are more popular among men than women\n",
      "- Which type of footwear is most popular among adults\n",
      "- The total number of shoes sold in a particular month\"\n",
      "Response: \"The total number of shoes sold in a particular month cannot be determined from the database, as it does not contain any sales data.\"\n",
      "\n",
      "Example 3:\n",
      "Question: \"A search engine has a trend-tracking feature that provides information on how popular a search term is. The data can be filtered by geographic region, date, and category. Categories include arts and entertainment, computers and electronics, games, news, people and society, shopping, sports, and travel. Which of the following questions is LEAST likely to be answerable using the trends feature?\"\n",
      "Options: \"- In what month does a particular sport receive the most searches?\n",
      "- In which political candidates are people interested?\n",
      "- What is the cost of a certain electronics product?\n",
      "- Which region of the country has the greatest number of people searching for opera performances?\"\n",
      "Response: \"In what is the cost of a certain electronics product?\"\n",
      "\n",
      "Example 4:\n",
      "Question: \"A digital photo file contains data representing the level of red, green, and blue for each pixel in the photo. The file also contains metadata that describe the date and geographic location where the photo was taken. For which of the following goals would analyzing the metadata be more appropriate than analyzing the data?\"\n",
      "Options: \"- Determining the likelihood that the photo is a picture of the sky\n",
      "- Determining the likelihood that the photo was taken at a particular public event\n",
      "- Determining the number of people that appear in the photo\n",
      "- Determining the usability of the photo for projection onto a particular color background\"\n",
      "Response: \"Determining the likelihood that the photo was taken at a particular public event.\"\n",
      "\n",
      "Example 5:\n",
      "Question: \"A program is expressed in a programming language. Which of the following is true of the program?\"\n",
      "Options: \"- The program can also be expressed as binary code, but will be more easily understood by humans when expressed in a higher-level programming language.\n",
      "- The program can also be expressed as binary code, which will reduce the likelihood of errors.\n",
      "- The program cannot be expressed as binary code, because binary code can only be used to represent data.\n",
      "- Some parts of the program can be expressed as binary code, but operations must be expressed using a higher-level programming language.\"\n",
      "Response: \"The program can also be expressed as binary code, but will be more easily understood by humans when expressed in a higher-level programming language.\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Based solely on these examples, predict the most likely response from the black-box model to this new question. \n",
      "New Question: A large data set contains information about all students majoring in computer science in colleges across the United States. The data set contains the following information about each student.\n",
      "   ° The student's gender\n",
      "   ° The state in which the student attends college\n",
      "   ° The student's grade point average on a 4.0 scale\n",
      "\n",
      " Which of the following questions could be answered by analyzing only information in the data set?\n",
      "Options: - Do students majoring in computer science tend to have higher grade point averages than students majoring in other subjects?\n",
      "- How many states have a higher percentage of female computer science majors than male computer science majors attending college in that state?\n",
      "- What percent of students attending college in a certain state are majoring in computer science?\n",
      "- Which college has the highest number of students majoring in computer science?\n",
      "Your Predicted Black-box LLM Response: (Exact response text only)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = -1\n",
    "j +=1\n",
    "print(j)\n",
    "\n",
    "print(f\"zero_shot_response\")\n",
    "print(f\"{ds_a2d['zero_shot_response'][j]}\")\n",
    "print(f\"few_shot_response\")\n",
    "print(f\"{ds_a2d['few_shot_response'][j]}\")\n",
    "print(f\"black_box_response\")\n",
    "print(f\"{ds_a2d['black_box_response'][j]}\")\n",
    "\n",
    "print(\"zero_shot_top_index\")\n",
    "print(f\"{ds_a2d['zero_shot_top_index'][j]}\")\n",
    "print(\"few_shot_top_index\")\n",
    "print(f\"{ds_a2d['few_shot_top_index'][j]}\")\n",
    "print(\"cosine similarity between zero shot picked option and the prompt\")\n",
    "print(f\"{ds_a2d['prompt_pick_cosine_sim_zero'][j]}\")\n",
    "print(\"cosine similarity between few shot picked option and the prompt\")\n",
    "print(f\"{ds_a2d['prompt_pick_cosine_sim_few'][j]}\")\n",
    "print(f\"prompt\")\n",
    "print(f\"{ds_a2d['prompt'][j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['zero_shot_response', 'few_shot_response', 'black_box_response', 'prompt', 'zero_shot_top_index', 'few_shot_top_index', 'prompt_pick_cosine_sim_zero', 'prompt_pick_cosine_sim_few'],\n",
       "    num_rows: 29\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds_a2d\n",
    "ds_d2a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
